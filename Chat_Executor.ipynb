{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5TwMbBvpk4K"
      },
      "source": [
        "# 02. Learning LangGraph - Chat Executor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAoQEqlXGrWi",
        "outputId": "02509019-f945-403b-a92a-2d376e592ac4"
      },
      "outputs": [],
      "source": [
        "# !pip install --quiet -U langchain langchain_openai langgraph langchainhub langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL-NMZ7ve3Sl"
      },
      "source": [
        "modified from https://github.com/langchain-ai/langgraph/blob/main/examples/chat_agent_executor_with_function_calling/base.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# importing os module for environment variables\n",
        "import os\n",
        "# importing necessary functions from dotenv library\n",
        "from dotenv import load_dotenv, dotenv_values \n",
        "# loading variables from .env file\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "api_key = os.getenv('PRACTICE_KEY')\n",
        "langchain_api_key = os.getenv('LANGCHAIN_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "guac0Zh7Gz4Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = langchain_api_key\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph_02\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGkci88EkVwj"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "58MBHiikkQDb"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(temperature=0, streaming=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_I3howTkdUw"
      },
      "source": [
        "## Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OLeIVeaEJltj"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
        "import random\n",
        "\n",
        "@tool(\"lower_case\", return_direct=True)\n",
        "def to_lower_case(input:str) -> str:\n",
        "  \"\"\"Returns the input as all lower case.\"\"\"\n",
        "  return input.lower()\n",
        "\n",
        "@tool(\"random_number\", return_direct=True)\n",
        "def random_number_maker(input:str) -> str:\n",
        "    \"\"\"Returns a random number between 0-100. input the word 'random'\"\"\"\n",
        "    return random.randint(0, 100)\n",
        "\n",
        "tools = [to_lower_case,random_number_maker]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IQkcYH78mRmk"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
        "\n",
        "tool_executor = ToolExecutor(tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aqJWD8X1ke5q"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\bhaiyasingh\\Documents\\llm_env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The function `format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.3.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "\n",
        "functions = [format_tool_to_openai_function(t) for t in tools]\n",
        "model = model.bind_functions(functions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRyUkY3cktGP"
      },
      "source": [
        "## AgentState"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I1H-xbWNkpSv"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated, Sequence\n",
        "import operator\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbQtOmzQk27f"
      },
      "source": [
        "## Nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2HoxaGZbkvi5"
      },
      "outputs": [],
      "source": [
        "from langchain_core.agents import AgentFinish\n",
        "from langgraph.prebuilt import ToolInvocation\n",
        "import json\n",
        "from langchain_core.messages import FunctionMessage\n",
        "\n",
        "# Define the function that determines whether to continue or not\n",
        "def should_continue(state):\n",
        "    messages = state['messages']\n",
        "    last_message = messages[-1]\n",
        "    # If there is no function call, then we finish\n",
        "    if \"function_call\" not in last_message.additional_kwargs:\n",
        "        return \"end\"\n",
        "    # Otherwise if there is, we continue\n",
        "    else:\n",
        "        return \"continue\"\n",
        "\n",
        "# Define the function that calls the model\n",
        "def call_model(state):\n",
        "    messages = state['messages']\n",
        "    response = model.invoke(messages)\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# Define the function to execute tools\n",
        "def call_tool(state):\n",
        "    messages = state['messages']\n",
        "    # Based on the continue condition\n",
        "    # we know the last message involves a function call\n",
        "    last_message = messages[-1]\n",
        "\n",
        "    print('last_message = ', last_message)\n",
        "\n",
        "    # We construct an ToolInvocation from the function_call\n",
        "    action = ToolInvocation(\n",
        "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
        "        tool_input=json.loads(last_message.additional_kwargs[\"function_call\"][\"arguments\"]),\n",
        "    )\n",
        "    print(f\"The agent action is {action}\")\n",
        "    # We call the tool_executor and get back a response\n",
        "    response = tool_executor.invoke(action)\n",
        "    print(f\"The tool result is: {response}\")\n",
        "    # We use the response to create a FunctionMessage\n",
        "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [function_message]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvaLZp3jlM9F"
      },
      "source": [
        "## Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2Vxw2TOClGYm"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "# Define a new graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Define the two nodes we will cycle between\n",
        "workflow.add_node(\"agent\", call_model)\n",
        "workflow.add_node(\"action\", call_tool)\n",
        "\n",
        "# Set the entrypoint as `agent` where we start\n",
        "workflow.set_entry_point(\"agent\")\n",
        "\n",
        "# We now add a conditional edge\n",
        "workflow.add_conditional_edges(\n",
        "    # First, we define the start node. We use `agent`.\n",
        "    # This means these are the edges taken after the `agent` node is called.\n",
        "    \"agent\",\n",
        "    # Next, we pass in the function that will determine which node is called next.\n",
        "    should_continue,\n",
        "    # Finally we pass in a mapping.\n",
        "    # The keys are strings, and the values are other nodes.\n",
        "    # END is a special node marking that the graph should finish.\n",
        "    # What will happen is we will call `should_continue`, and then the output of that\n",
        "    # will be matched against the keys in this mapping.\n",
        "    # Based on which one it matches, that node will then be called.\n",
        "    {\n",
        "        # If `tools`, then we call the tool node.\n",
        "        \"continue\": \"action\",\n",
        "        # Otherwise we finish.\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "# We now add a normal edge from `tools` to `agent`.\n",
        "# This means that after `tools` is called, `agent` node is called next.\n",
        "workflow.add_edge('action', 'agent')\n",
        "\n",
        "# Finally, we compile it!\n",
        "# This compiles it into a LangChain Runnable,\n",
        "# meaning you can use it as you would any other runnable\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAVFBk3GlY5-"
      },
      "source": [
        "## Run it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELSoxDK_lRO_",
        "outputId": "5882db0a-eeea-4094-ee36-d21ca8d0e46c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "last_message =  content='' additional_kwargs={'function_call': {'arguments': '{\"input\":\"random\"}', 'name': 'random_number'}} response_metadata={'finish_reason': 'function_call'} id='run-8eefd2c8-c5f5-4f56-84ac-a820c0e0aa20-0'\n",
            "The agent action is tool='random_number' tool_input={'input': 'random'}\n",
            "The tool result is: 43\n",
            "last_message =  content='' additional_kwargs={'function_call': {'arguments': '{\"input\":\"forty-three\"}', 'name': 'lower_case'}} response_metadata={'finish_reason': 'function_call'} id='run-417bfcd9-16d6-48f3-80ce-44bae85c67dd-0'\n",
            "The agent action is tool='lower_case' tool_input={'input': 'forty-three'}\n",
            "The tool result is: forty-three\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': [SystemMessage(content='you are a helpful assistant'),\n",
              "  HumanMessage(content='give me a random number and then write in words and make it lower case'),\n",
              "  AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"random\"}', 'name': 'random_number'}}, response_metadata={'finish_reason': 'function_call'}, id='run-8eefd2c8-c5f5-4f56-84ac-a820c0e0aa20-0'),\n",
              "  FunctionMessage(content='43', name='random_number'),\n",
              "  AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"forty-three\"}', 'name': 'lower_case'}}, response_metadata={'finish_reason': 'function_call'}, id='run-417bfcd9-16d6-48f3-80ce-44bae85c67dd-0'),\n",
              "  FunctionMessage(content='forty-three', name='lower_case'),\n",
              "  AIMessage(content='The random number is 43, and in words, it is \"forty-three\" in lower case.', response_metadata={'finish_reason': 'stop'}, id='run-0fb914a9-71dc-4b74-afb5-892488fd7e80-0')]}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "# inputs = {\"input\": \"give me a random number and then write in words and make it lower case\", \"chat_history\": []}\n",
        "\n",
        "system_message = SystemMessage(content=\"you are a helpful assistant\")\n",
        "user_01 = HumanMessage(content=\"give me a random number and then write in words and make it lower case\")\n",
        "# user_01 = HumanMessage(content=\"plear write 'Merlion' in lower case\")\n",
        "# user_01 = HumanMessage(content=\"what is a Merlion?\")\n",
        "\n",
        "inputs = {\"messages\": [system_message,user_01]}\n",
        "\n",
        "app.invoke(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhW-wd2Olh6H",
        "outputId": "30b3aa2b-f74a-4956-ca91-39b5caf8d9ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "last_message =  content='' additional_kwargs={'function_call': {'arguments': '{\"input\":\"Merlion\"}', 'name': 'lower_case'}} response_metadata={'finish_reason': 'function_call'} id='run-25351cc4-b911-4b1d-9c90-eb33ce9ff96f-0'\n",
            "The agent action is tool='lower_case' tool_input={'input': 'Merlion'}\n",
            "The tool result is: merlion\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': [SystemMessage(content='you are a helpful assistant'),\n",
              "  HumanMessage(content=\"plear write 'Merlion' in lower case\"),\n",
              "  AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"Merlion\"}', 'name': 'lower_case'}}, response_metadata={'finish_reason': 'function_call'}, id='run-25351cc4-b911-4b1d-9c90-eb33ce9ff96f-0'),\n",
              "  FunctionMessage(content='merlion', name='lower_case'),\n",
              "  AIMessage(content='The word \"Merlion\" in lower case is \"merlion\".', response_metadata={'finish_reason': 'stop'}, id='run-d0202527-375b-4c58-b6b1-58c53024e17b-0')]}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "# inputs = {\"input\": \"give me a random number and then write in words and make it lower case\", \"chat_history\": []}\n",
        "\n",
        "system_message = SystemMessage(content=\"you are a helpful assistant\")\n",
        "# user_01 = HumanMessage(content=\"give me a random number and then write in words and make it lower case\")\n",
        "user_01 = HumanMessage(content=\"plear write 'Merlion' in lower case\")\n",
        "# user_01 = HumanMessage(content=\"what is a Merlion?\")\n",
        "\n",
        "inputs = {\"messages\": [system_message,user_01]}\n",
        "\n",
        "app.invoke(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdwMgR5Ag6pi",
        "outputId": "f107fe06-29e5-4686-de05-2612956e9fef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [SystemMessage(content='you are a helpful assistant'),\n",
              "  HumanMessage(content='what is a Merlion?'),\n",
              "  AIMessage(content='A Merlion is a mythical creature with the head of a lion and the body of a fish. It is a symbol of Singapore and is often seen as a mascot representing the city-state. The Merlion is a popular tourist attraction in Singapore, with statues of the creature located at various spots around the country.', response_metadata={'finish_reason': 'stop'}, id='run-3a50c452-90c6-470e-bebf-514823d495e8-0')]}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "# inputs = {\"input\": \"give me a random number and then write in words and make it lower case\", \"chat_history\": []}\n",
        "\n",
        "system_message = SystemMessage(content=\"you are a helpful assistant\")\n",
        "# user_01 = HumanMessage(content=\"give me a random number and then write in words and make it lower case\")\n",
        "# user_01 = HumanMessage(content=\"plear write 'Merlion' in lower case\")\n",
        "user_01 = HumanMessage(content=\"what is a Merlion?\")\n",
        "\n",
        "inputs = {\"messages\": [system_message,user_01]}\n",
        "\n",
        "app.invoke(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llm_env",
      "language": "python",
      "name": "llm_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
